{
    "projects":[
       {
          "id":1,
          "title":"Projet A79",
          "description":"Comptage poids lourds avec l'intelligence artificielle.",
          "image":"assets/projets/entete/projetA79.png"
       },
       {
          "id":2,
          "title":"Projet Cerema",
          "description":"Tièrce maintenance applicative.",
          "image":"assets/projets/entete/projetCerema.png"
       },
       {
          "id":3,
          "title":"RAG",
          "description":"Génération augmentée de récupération.",
          "image":"./assets/projets/entete/rag.png"
       }
    ],
    "projectDetails":[
       {
          "id":1,
          "title":"Projet A79",
          "description":"Comptage de véhicules dans les aires de repos grâce à l'intelligence artificielle",
          "image":"assets/projets/entete/projetA79.png",
          "roleItems":[
             "Entrainement de l'IA",
             "Paramètrage des controlleurs",
             "Retours de performances sur autoroutes"
          ],
          "technologies":[
             "YOLO",
             "Linux",
             "SSH",
             "RTSP"
          ],
          "results":[
             "Réduction du temps de traitement des incidents critiques de 30%.",
             "Mise en place d’un pipeline CI/CD pour des déploiements plus rapides.",
             "Amélioration de la satisfaction des utilisateurs finaux grâce à une interface modernisée.",
             "Renforcement de la sécurité grâce à des audits réguliers et des mises à jour proactives."
          ],
          "information":[
            {
               "title": "Introduction",
               "image": "./assets/projets/a79/comment_compté_1.png",
               "image2":"./assets/projets/a79/comment_compté_2.png",
               "content": "Le projet consiste à compter les véhicules présents dans les aires d'autoroute afin d'indiquer sur des panneaux numériques le nombre de places restantes. Le comptage est réalisé par Yolo4, un algorithme capable de détecter les objets au premier regard, en effectuant la détection et la classification simultanément. Cycounter, notre outil permettant le traitement des résultats de Yolo8, fonctionne de la manière suivante :",
               "content2" : "Une fois le camion entré dans le cadre jaune, il est compté +1 pour l'entrée de l'aire de repos. Idem pour la sortie, où il sera compté -1",
               "class": "introduction",
               "size": "petit"
            },
            {
               "title":"Mon rôle",
               "content": "Le projet vise à compter les véhicules présents dans les aires d'autoroute afin d'afficher sur des panneaux numériques le nombre de places restantes. Pour ce faire, nous utilisons Yolo4, un algorithme capable de détecter et de classifier les objets simultanément. Cette technologie permet de fournir des informations en temps réel aux conducteurs, améliorant ainsi la gestion des aires de repos et facilitant la recherche de places disponibles pour les usagers de la route.",
               "content2": "Mon rôle dans ce projet fut la création d'une documentation détaillée, couvrant la définition des classes, l'installation de l'architecture et des serveurs, ainsi que l'entraînement et les tests. J'ai également redéfini le modèle en modifiant les classes et en effectuant des annotations, et j'ai créé les fichiers de poids pour Yolo8 en entraînant plusieurs versions et en appliquant des augmentations. De plus, j'ai mis en place les contrôleurs pour Yolo8 sur le terrains en installant Ubuntu 22, en configurant le réseau, et en mettant en service l'outil de comptage sur les aires de repos., développé une application Python pour récupérer les vidéos des contrôleurs (sur sites)",
               "class": "introduction"
            },
            {
               "title": "Modèles",
               "image": "./assets/projets/a79/détection_de_nuit.png",
               "image2": "./assets/projets/a79/détection_multiple.png",
               "content": "Pour fonctionner, Yolo a besoin d'un modèle, une banque d'images, où chaque image est accompagnée d'un fichier texte précisant l'emplacement et les classes des véhicules présents sur l'image.",
               "content2": "J'ai dû réannoter les images de l'ancien modèle et ajouter plus de 1000 images pour que notre modèle soit spécifiquement entraîné à identifier et classer des objets appartenant aux catégories suivantes : voiture, van, camion, bus et autres. J'ai aussi ajouté des centaines d'images de nuit car l'ancien modèle avait des lacunes. Maintenant, le modèle est plus que performant.",
               "size": "grand"
            },
            {
               "title": "Entrainement",
               "image": "./assets/projets/a79/metric.png",
               "content": "Une fois notre modèle annoté, il nous faut entraîner Yolo8 sur celui-ci. Mon rôle ici était de comprendre la démarche pour adapter notre outil qui facilite cette création. J'ai utilisé la configuration \"predict\" pour le modèle Yolo, en ajustant les paramètres tels que le nombre d'epochs (nombre de passages de l'IA sur le modèle). Le modèle YOLO a été initialisé avec des poids pré-entraînés sur un grand ensemble de données, comme COCO (Common Objects in Context). Cette initialisation permet au modèle de bénéficier de connaissances préalables sur la détection d'objets. Le processus d'entraînement utilise toutes nos images annotées. Le modèle ajuste ses poids et ses paramètres à chaque itération pour minimiser la différence entre ses prédictions et les annotations fournies. J'ai, dans un second temps, ajusté les hyperparamètres tels que le taux de rotation des images et la saturation des couleurs pour optimiser les performances du modèle.",
               "content2" : "Une fois l'entraînement terminé, le modèle est testé sur des images qu'il n'a jamais vues pour évaluer ses performances en détection d'objets. Nos résultats sont enregistrés sous forme de tableaux et de graphiques. Les données mAP50 et mAP50-95 nous permettent de savoir si l'entraînement est concluant ou non. Plus les valeurs se rapprochent de 1, plus le modèle est performant.",
               "size": "moyen"
            },
            {
               "title": "Création des contrôleurs",
               "content": "Pour passer notre projet sur Yolo8, nous avons dû refaire les contrôleurs à partir de zéro. Pour cela, j'ai dû recréer un contrôleur type. J'ai d'abord installé Ubuntu 22.04 et l'ai configuré sur le réseau de manière à y avoir accès depuis notre laboratoire jusqu'à mon bureau, en passant par SSH ou Samba, un logiciel nous permettant d'accéder à notre contrôleur à partir d'une interface d'explorateur de fichiers. Ensuite, j'ai dû installer Python, les drivers Nvidia ainsi que le Cuda toolkit, qui permettent de lancer l'outil de comptage de poids lourds développé en Python et d'utiliser pleinement la carte graphique de notre contrôleur, qui est fortement sollicitée lors des détections avec Yolo. Pour finir, j'ai installé notre outil de comptage et les configurations des aires de repos pour une implémentation sur site. J'ai aussi implémenté nos tests pour vérifier que notre contrôleur est capable d'utiliser Yolo ainsi que de traiter des flux RTSP, ceux fournis par les caméras des aires de repos.",
               "size": "grand",
               "class": "introduction"
            }
          ]
       },
       {
          "id":2,
          "title":"Projet Cerema",
          "description":"En tant que prestataire, j’ai participé à un projet de tierce maintenance applicative (TMA) pour le CEREMA. L’objectif principal était de garantir la disponibilité, la performance et l’évolutivité des applications utilisées par cet organisme public stratégique.",
          "image":"assets/projets/entete/projetCerema.png",
          "roleItems":[
             "Analyse et résolution des anomalies signalées par les utilisateurs.",
             "Développement de nouvelles fonctionnalités selon les besoins du CEREMA.",
             "Amélioration continue des performances et de la sécurité des applications.",
             "Rédaction de documentations techniques pour faciliter la transmission des connaissances."
          ],
          "technologies":[
             "Java",
             "SpringBoot",
             "Angular",
             "Postgres / Postgis / H2",
             "Docker",
             "Git"
          ],
          "results":[
             "Ajout de fonctionnalités diverses.",
             "Mise en place de tests unitaires et tests d'intégrations.",
             "Renforcement de la sécurité des applications.",
             "Dockerisation des applications pour une mise en recette Eiffate.",
             "Satisfactions du client."
          ],
          "information": [
            {
               "title": "Introduction",
               "content": "Le projet CEREMA est un projet de TTMA (tierce maintenance multi-applicative). Cela signifie que nous nous chargeons des applications du Cerema pour les maintenir ou ajouter de nouvelles fonctionnalités. Le client nous met à disposition le code sur Gitlab, nous fait part de ses besoins grâce à l'outil Projektor, puis nous commande les tickets nécessaires.",
               "content2": "Une fois cela fait, nous étudions la demande et fournissons un chiffrage (nombre de jours-homme que nous vendons pour réaliser la demande). Si le chiffrage est accepté, nous commençons les développements et livrons le résultat sur le Gitlab du client.",
               "class": "introduction",
               "size": "petit"
            },
            {
               "title": "Mon rôle",
               "content": "Dans ce projet, j'ai eu l'occasion de passer par toutes les étapes de la gestion d'un projet de TTMA. J'ai réalisé des \"prises en compte produit\", c'est-à-dire que j'ai étudié les applications du client, compris ce qui fonctionne (et ce qui ne fonctionne pas), fouiné pour savoir s'il n'y avait pas d'énormités. Et j'ai informé le client de ce qui allait ou non en l'incitant à commander des mises à niveau.",
               "content2": "J'ai pu développer les fonctionnalités demandées sur une multitude d'applications n'ayant aucun rapport au niveau métier. Par exemple, une application de gestion des ressources humaines, une application de gestion des eaux usées et de l'assainissement, une application de suivi des ressources minérales sous forme de carte de la France, une application de suivi des utilisations des gares sous forme de carte de la France, et une application de conseil aux collectivités sur le choix des plantes à utiliser en fonction de multiples critères."
            },
            {
               "title": "Outils",
               "image": "./assets/projets/cerema/angular.png",
               "image2": "./assets/projets/cerema/spring.png",
               "content": "Lors de mon expérience au Cerema, j'ai intégré l'équipe Java Web, où j'ai travaillé avec les frameworks Angular (pour le front-end) et Spring Boot (pour le back-end).J'ai débuté par une formation de trois jours sur Angular, axée sur les bases du framework. Le fil rouge de cette formation consistait en la réalisation d'une application consommant une API interne à Clemessy, permettant d'obtenir un token d'accès à une liste de contrôleurs. Cette formation m’a permis de me familiariser avec Angular et d’acquérir les bonnes pratiques avant de contribuer aux applications développées au Cerema.En parallèle, j’ai progressivement appris à utiliser Spring Boot, un framework orienté back-end facilitant le développement d'applications web et de microservices.",
               "content2": "J’ai pu approfondir mes compétences en travaillant notamment sur les dizaines d'applications que nous maintenons",
               "size": "tres-petit"
            },
            {
               "title": "SESAME",
               "image": "./assets/projets/cerema/questionnaire.png",
               "image2": "./assets/projets/cerema/resultat.png",
               "content": "Destiné en particulier aux collectivités, Sésame permet d’identifier les espèces les plus à même de produire les services attendus dans le cadre de projets d’aménagement ou de végétalisation. L’application est constituée d’un grand formulaire pour chaque collectivité et ensuite, l’application propose un lot de plantes adapté aux besoins.",
               "content2": "Lorsque nous avons récupéré l’application, SESAME s’occupait de deux collectivités (Metz et Moselle), et le code était en «dur». L’objectif était de rendre l’application modulaire à toutes les collectivités et leurs spécificités, ainsi que de créer un moyen d’importer les données des nouvelles collectivités collaborantes (comme Angoulême).",
               "size": "moyen",
               "class": "introduction"
            },
            {
               "title": "SODA",
               "content": "SODA est une application RH proposant un suivi des candidats pour les fiches de postes du CEREMA. Plusieurs candidats postulent à une fiche de poste et les RH choisissent la meilleure candidature, et remplissent des formulaires pour valider l’embauche.",
               "content2": "Mon travail sur ce projet était des résolutions de tickets diverses. Tel que la réalisation des 2 dernières étapes. Étapes de validation automatique lors de l’arrivée du candidat et l’étape de la signature de la candidature avec l’envoi du document sur le cloud. Ou encore la communication avec l’application PIRAMID (application RH répertoriant tous les employés) pour mettre à jour les modifications des futurs employés."
            },
            {
               "title": "RESILIEAU",
               "content": "Lors de la prise en compte d’un résiliau, j’ai identifié une erreur dans le code qui introduisait une faille d’injection. En effectuant des tests avec Postman, j’ai constaté qu’il était possible de modifier son propre identifiant dans la requête HTTP et ainsi accéder ou altérer les données d’autres utilisateurs. Cette vulnérabilité représentait un risque majeur en matière de sécurité et de confidentialité. J’ai alors remonté l’anomalie et travaillé à la mise en place de contrôles renforcés côté serveur (vérification des droits et filtrage des paramètres) afin de corriger la faille et sécuriser l’application."
            }
         ]
       },
       {
         "id":3,
         "title":"Génération augmentée de récupération",
         "description":"Développement d'un système de question-réponse basé sur des documents internes, combinant la recherche sémantique avec des modèles LLM.",
         "image":"./assets/proœjets/entete/rag.png",
         "roleItems":[
            "Mise en place de la base vectorielle pour indexation des documents",
            "Intégration d’un modèle LLM avec gestion du contexte",
            "(Futur) Création d’un frontend de démonstration pour les utilisateurs"
         ],
         "technologies":[
            "Python",
            "LangChain",
            "Mistral API",
            "Docker"
         ],
         "results":[
            "Aide à la recherche des réponses grâce au LLM.",
            "Réduction du temps de recherche d’information dans les documents internes.",
            "Création d’une preuve de concept validée par les utilisateurs métiers.",
            "(Futur) Architecture scalable et facilement déployable en local ou dans le cloud."
         ],
         "information":[
            {
               "title":"Introduction",
               "content":"Le projet RAG (Retrieval-Augmented Generation) vise à concevoir une application intelligente capable de répondre aux questions des utilisateurs à partir d’un ensemble de documents internes (PDF, DOCX, etc.). Le système s’appuie sur une base vectorielle et un modèle de génération de texte pour fournir des réponses contextualisées et précises.",
               "content2":"Le RAG associe la recherche documentaire (retrieval) avec la génération de texte (generation), ce qui sort des réponses pertinentes même en dehors des cas d'entrainements du modèle.",
               "size":"moyen"
            },
            {
               "title":"Mon rôle",
               "content":"J’ai été en charge  de l’architecture du projet : vectorisation (via des embeddings) des textes / documents, tests sur l'API Mitral. Création du code Python pour créer une interface utilisateur.",
               "content2":""
            },
            {
               "title":"Fonctionnement du RAG",
               "image":"./assets/projets/rag/rag_1.png",
               "content":"Le fonctionnement du RAG commence par la segmentation des documents en chunks (morceaux de 1000 caractères) cohérents. Chaque chunk est ensuite transformé en vecteur à l’aide d’un modèle d’embedding. Ces vecteurs sont stockés dans une base vectorielle (FAISS). Lorsqu’une question est posée, elle est elle-même vectorisée puis comparée aux vecteurs de la base afin de retrouver les passages les plus pertinents.",
               "content2":"Les passages récupérés sont ensuite injectés dans le prompt du LLM (Mistral AI), qui génère la réponse à la question posée.",
               "class": "introduction",
               "size":"moyen"
            },
            {
               "title":"Déploiement et tests",
               "content":"(Futur) Le projet sera dockerisé (mis en boite pour le déploiement) pour simplifier le déploiement. Des tests de charge seront effectués pour valider les performances du système sous différentes charges d’utilisateurs. Des métriques de pertinence et de satisfaction utilisateur seront réalisées.",
               "content2":"",
               "size":"moyen"
            }
         ]
       }
    ]
 }
